{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WildGuard Exploration Notebook\n",
    "\n",
    "This notebook explores the WildChat detection results to identify patterns, prevalence rates, and interesting findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from src.utils import load_jsonl, load_json\n",
    "from src.config import OUTPUTS_DIR, FIGURES_DIR, DARK_PATTERN_CATEGORIES\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WildChat detections\n",
    "detections = load_jsonl(OUTPUTS_DIR / 'wildchat_detections.jsonl')\n",
    "df = pd.DataFrame(detections)\n",
    "\n",
    "print(f'Total detections: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overall Prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prevalence by category\n",
    "category_counts = df['predicted_category'].value_counts()\n",
    "total = len(df)\n",
    "\n",
    "prevalence = pd.DataFrame({\n",
    "    'Category': category_counts.index,\n",
    "    'Count': category_counts.values,\n",
    "    'Rate': category_counts.values / total,\n",
    "    'Per 1000': 1000 * category_counts.values / total\n",
    "})\n",
    "\n",
    "print('\\nPrevalence by Category:')\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prevalence (excluding 'none')\n",
    "flagged_prev = prevalence[prevalence['Category'] != 'none'].sort_values('Per 1000', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(flagged_prev['Category'], flagged_prev['Per 1000'], color=sns.color_palette('husl', len(flagged_prev)))\n",
    "ax.set_xlabel('Prevalence (per 1,000 turns)')\n",
    "ax.set_title('Dark Pattern Prevalence by Category')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'prevalence_exploration.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confidence Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall confidence distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# All detections\n",
    "axes[0].hist(df['predicted_confidence'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Confidence Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('All Detections')\n",
    "\n",
    "# Flagged only (non-none)\n",
    "flagged = df[df['predicted_category'] != 'none']\n",
    "axes[1].hist(flagged['predicted_confidence'], bins=20, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].set_xlabel('Confidence Score')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Flagged Detections Only')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'confidence_exploration.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence by category\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "categories = [c for c in DARK_PATTERN_CATEGORIES if c in df['predicted_category'].values]\n",
    "conf_by_cat = [df[df['predicted_category'] == c]['predicted_confidence'].values for c in categories]\n",
    "\n",
    "bp = ax.boxplot(conf_by_cat, labels=categories, patch_artist=True)\n",
    "colors = sns.color_palette('husl', len(categories))\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.set_ylabel('Confidence Score')\n",
    "ax.set_title('Confidence Distribution by Category')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'confidence_by_category.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Turn Index Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection rate by turn index\n",
    "if 'turn_index' in df.columns:\n",
    "    turn_stats = df.groupby('turn_index').agg(\n",
    "        total=('predicted_category', 'count'),\n",
    "        flagged=('predicted_category', lambda x: (x != 'none').sum())\n",
    "    ).reset_index()\n",
    "    turn_stats['flag_rate'] = turn_stats['flagged'] / turn_stats['total']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.plot(turn_stats['turn_index'], turn_stats['flag_rate'], marker='o', linewidth=2, color='coral')\n",
    "    ax.fill_between(turn_stats['turn_index'], turn_stats['flag_rate'], alpha=0.3, color='coral')\n",
    "    ax.set_xlabel('Conversation Turn Index')\n",
    "    ax.set_ylabel('Flag Rate')\n",
    "    ax.set_title('Dark Pattern Detection Rate by Conversation Turn')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'flag_rate_by_turn.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nTurn Index Statistics:')\n",
    "    turn_stats.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Context Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis by model (if available)\n",
    "if 'model' in df.columns:\n",
    "    model_stats = df.groupby('model').agg(\n",
    "        total=('predicted_category', 'count'),\n",
    "        flagged=('predicted_category', lambda x: (x != 'none').sum())\n",
    "    ).reset_index()\n",
    "    model_stats['flag_rate'] = model_stats['flagged'] / model_stats['total']\n",
    "    model_stats = model_stats.sort_values('flag_rate', ascending=False)\n",
    "    \n",
    "    print('Flag Rate by Model:')\n",
    "    model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. High-Risk Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find high-confidence detections\n",
    "high_risk = df[(df['predicted_category'] != 'none') & (df['predicted_confidence'] > 0.7)]\n",
    "high_risk = high_risk.sort_values('predicted_confidence', ascending=False)\n",
    "\n",
    "print(f'High-risk detections (confidence > 0.7): {len(high_risk)}')\n",
    "print(f'\\nTop categories in high-risk:')\n",
    "print(high_risk['predicted_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample high-risk content\n",
    "print('\\n=== Sample High-Risk Detections ===')\n",
    "for i, row in high_risk.head(5).iterrows():\n",
    "    print(f\"\\n--- {row['predicted_category']} (conf: {row['predicted_confidence']:.2f}) ---\")\n",
    "    content = row.get('content', 'N/A')\n",
    "    print(content[:300] + '...' if len(content) > 300 else content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('=== WildGuard Exploration Summary ===')\n",
    "print(f'\\nTotal samples analyzed: {len(df)}')\n",
    "print(f'Flagged samples: {len(df[df[\"predicted_category\"] != \"none\"])}')\n",
    "print(f'Overall flag rate: {len(df[df[\"predicted_category\"] != \"none\"]) / len(df):.1%}')\n",
    "print(f'\\nMean confidence (flagged): {flagged[\"predicted_confidence\"].mean():.2f}')\n",
    "print(f'High-risk detections (>0.7 conf): {len(high_risk)}')\n",
    "\n",
    "print('\\n=== Key Findings ===')\n",
    "top_cat = prevalence[prevalence['Category'] != 'none'].iloc[0]\n",
    "print(f'- Most common pattern: {top_cat[\"Category\"]} ({top_cat[\"Per 1000\"]:.1f} per 1000 turns)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
